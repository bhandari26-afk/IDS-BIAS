{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e79e145c-6192-459c-9ec8-a8c6b8d2045a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset loaded: (100000, 72)\n",
      "‚ö† Dropping non-numeric columns: ['Source_File']\n",
      "Train shape: (70000, 70), Validation shape: (30000, 70)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import yaml\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load config\n",
    "with open(\"../config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Paths\n",
    "notebook_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "root_dir = os.path.abspath(os.path.join(notebook_dir, \"..\"))\n",
    "\n",
    "preprocessed_path = os.path.join(root_dir, \"data/processed/sample_preprocessed.csv\")\n",
    "models_dir = os.path.join(root_dir, \"models\")\n",
    "results_dir = os.path.join(root_dir, \"results\")\n",
    "\n",
    "target_col = config[\"data\"][\"target\"]\n",
    "\n",
    "# Load preprocessed data\n",
    "df = pd.read_csv(preprocessed_path)\n",
    "print(\"‚úÖ Dataset loaded:\", df.shape)\n",
    "\n",
    "# Drop non-numeric columns\n",
    "non_numeric_cols = df.select_dtypes(exclude=[\"number\"]).columns\n",
    "if len(non_numeric_cols) > 0:\n",
    "    print(f\"‚ö† Dropping non-numeric columns: {list(non_numeric_cols)}\")\n",
    "    df = df.drop(columns=non_numeric_cols)\n",
    "\n",
    "# Features and labels\n",
    "X = df.drop(columns=[target_col])\n",
    "y = pd.Categorical(df[target_col]).codes\n",
    "\n",
    "# Train/Validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(f\"Train shape: {X_train.shape}, Validation shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70b05a9c-8536-4ac7-aef9-c17e66ffa1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhand\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check: starting bias scenario run...\n",
      "\n",
      "--- GENDER_MALE_BIAS ---\n",
      "\n",
      "üîπ Running scenario: gender_male_bias\n",
      "‚úÖ Model trained.\n",
      "Confusion Matrix (first 5x5 block):\n",
      " [[12580     0     0     1     2]\n",
      " [    6     5     0     0     0]\n",
      " [    1     0   706     0     0]\n",
      " [    1     0     0    56     0]\n",
      " [   11     0     0     0   969]]\n",
      "\n",
      "Classification Report (head):\n",
      "   precision    recall  f1-score  support\n",
      "0   0.997858  0.999047  0.998452  12592.0\n",
      "1   1.000000  0.454545  0.625000     11.0\n",
      "2   1.000000  0.998586  0.999292    707.0\n",
      "3   0.982456  0.982456  0.982456     57.0\n",
      "4   0.997940  0.988776  0.993337    980.0\n",
      "‚úÖ Metrics saved to C:\\Users\\bhand\\ids-bias-project\\results\\bias_gender_male_bias.json\n",
      "‚è±Ô∏è Time taken: 6.98 seconds\n",
      "\n",
      "--- GENDER_FEMALE_BIAS ---\n",
      "\n",
      "üîπ Running scenario: gender_female_bias\n",
      "‚úÖ Model trained.\n",
      "Confusion Matrix (first 5x5 block):\n",
      " [[12548     2     0     1     4]\n",
      " [    9     3     0     0     0]\n",
      " [    2     0   747     0     0]\n",
      " [    3     0     0    55     0]\n",
      " [   11     0     0     0   945]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhand\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\bhand\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\bhand\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (head):\n",
      "   precision    recall  f1-score  support\n",
      "0   0.996664  0.998965  0.997813  12561.0\n",
      "1   0.600000  0.250000  0.352941     12.0\n",
      "2   1.000000  0.997330  0.998663    749.0\n",
      "3   0.982143  0.948276  0.964912     58.0\n",
      "4   0.994737  0.988494  0.991605    956.0\n",
      "‚úÖ Metrics saved to C:\\Users\\bhand\\ids-bias-project\\results\\bias_gender_female_bias.json\n",
      "‚è±Ô∏è Time taken: 6.42 seconds\n",
      "\n",
      "--- REGION_EU_BIAS ---\n",
      "\n",
      "üîπ Running scenario: region_eu_bias\n",
      "‚úÖ Model trained.\n",
      "Confusion Matrix (first 5x5 block):\n",
      " [[6284    0    1    0    2]\n",
      " [   4    3    0    0    0]\n",
      " [   0    0  374    0    0]\n",
      " [   0    0    0   25    0]\n",
      " [   5    0    0    0  484]]\n",
      "\n",
      "Classification Report (head):\n",
      "   precision    recall  f1-score  support\n",
      "0   0.997619  0.998887  0.998253   6291.0\n",
      "1   1.000000  0.428571  0.600000      7.0\n",
      "2   0.997333  1.000000  0.998665    374.0\n",
      "3   1.000000  1.000000  1.000000     25.0\n",
      "4   0.995885  0.989775  0.992821    489.0\n",
      "‚úÖ Metrics saved to C:\\Users\\bhand\\ids-bias-project\\results\\bias_region_eu_bias.json\n",
      "‚è±Ô∏è Time taken: 3.19 seconds\n",
      "\n",
      "--- REGION_ASIA_BIAS ---\n",
      "\n",
      "üîπ Running scenario: region_asia_bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhand\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\bhand\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\bhand\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model trained.\n",
      "Confusion Matrix (first 5x5 block):\n",
      " [[6293    0    1    1    0]\n",
      " [   3    1    0    0    0]\n",
      " [   1    0  332    0    0]\n",
      " [   3    0    0   29    0]\n",
      " [   7    0    1    0  483]]\n",
      "\n",
      "Classification Report (head):\n",
      "   precision    recall  f1-score  support\n",
      "0   0.997148  0.998730  0.997938   6301.0\n",
      "1   1.000000  0.250000  0.400000      4.0\n",
      "2   0.994012  0.996997  0.995502    333.0\n",
      "3   0.966667  0.906250  0.935484     32.0\n",
      "4   1.000000  0.983707  0.991786    491.0\n",
      "‚úÖ Metrics saved to C:\\Users\\bhand\\ids-bias-project\\results\\bias_region_asia_bias.json\n",
      "‚è±Ô∏è Time taken: 2.91 seconds\n",
      "\n",
      "‚úÖ All bias scenarios completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "# --- Helper Function ---\n",
    "def train_and_evaluate(X_train, y_train, X_val, y_val, scenario_name):\n",
    "    print(f\"\\nüîπ Running scenario: {scenario_name}\")\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        # Train model\n",
    "        model = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "        model.fit(X_train, y_train)\n",
    "        print(\"‚úÖ Model trained.\")\n",
    "\n",
    "        # Predict\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        # Confusion Matrix (show first part only)\n",
    "        cm = confusion_matrix(y_val, y_pred)\n",
    "        print(\"Confusion Matrix (first 5x5 block):\\n\", cm[:5, :5])\n",
    "\n",
    "        # Classification report\n",
    "        report = classification_report(y_val, y_pred, output_dict=True)\n",
    "        report_df = pd.DataFrame(report).transpose()\n",
    "        print(\"\\nClassification Report (head):\")\n",
    "        print(report_df.head())\n",
    "\n",
    "        # Save report\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "        save_path = os.path.join(results_dir, f\"bias_{scenario_name}.json\")\n",
    "        with open(save_path, \"w\") as f:\n",
    "            json.dump(report, f, indent=4)\n",
    "        print(f\"‚úÖ Metrics saved to {save_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in {scenario_name}: {e}\")\n",
    "    finally:\n",
    "        print(f\"‚è±Ô∏è Time taken: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "# --- Bias Scenario Simulation ---\n",
    "\n",
    "# Gender bias ‚Üí Assume rows 0-50% are \"Male\", 50-100% \"Female\"\n",
    "split_idx = len(X_train) // 2\n",
    "X_train_male, X_train_female = X_train.iloc[:split_idx], X_train.iloc[split_idx:]\n",
    "y_train_male, y_train_female = y_train[:split_idx], y_train[split_idx:]\n",
    "\n",
    "split_idx_val = len(X_val) // 2\n",
    "X_val_male, X_val_female = X_val.iloc[:split_idx_val], X_val.iloc[split_idx_val:]\n",
    "y_val_male, y_val_female = y_val[:split_idx_val], y_val[split_idx_val:]\n",
    "\n",
    "# Region bias ‚Üí Random split (simulating data from different regions)\n",
    "X_train_eu, X_train_asia, _, _ = np.array_split(X_train, 4)\n",
    "y_train_eu, y_train_asia, _, _ = np.array_split(y_train, 4)\n",
    "X_val_eu, X_val_asia, _, _ = np.array_split(X_val, 4)\n",
    "y_val_eu, y_val_asia, _, _ = np.array_split(y_val, 4)\n",
    "\n",
    "# --- Run scenarios ---\n",
    "scenarios = [\n",
    "    (\"gender_male_bias\", X_train_male, y_train_male, X_val_male, y_val_male),\n",
    "    (\"gender_female_bias\", X_train_female, y_train_female, X_val_female, y_val_female),\n",
    "    (\"region_eu_bias\", X_train_eu, y_train_eu, X_val_eu, y_val_eu),\n",
    "    (\"region_asia_bias\", X_train_asia, y_train_asia, X_val_asia, y_val_asia)\n",
    "]\n",
    "\n",
    "print(\"Sanity check: starting bias scenario run...\")\n",
    "for name, Xtr, ytr, Xv, yv in scenarios:\n",
    "    print(f\"\\n--- {name.upper()} ---\")\n",
    "    train_and_evaluate(Xtr, ytr, Xv, yv, name)\n",
    "\n",
    "print(\"\\n‚úÖ All bias scenarios completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f61e3499-b832-4c3e-b847-93d6118c424d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 40 samples from class 1. New train shape: (69960, 70)\n",
      "\n",
      "üîπ Running scenario: underrepresented_class1\n",
      "‚úÖ Model trained.\n",
      "Confusion Matrix (first 5x5 block):\n",
      " [[25133     0     1     2     2]\n",
      " [   17     6     0     0     0]\n",
      " [    3     0  1453     0     0]\n",
      " [    5     0     0   110     0]\n",
      " [   20     0     0     0  1916]]\n",
      "\n",
      "Classification Report (head):\n",
      "   precision    recall  f1-score  support\n",
      "0   0.997500  0.999205  0.998352  25153.0\n",
      "1   1.000000  0.260870  0.413793     23.0\n",
      "2   0.999312  0.997940  0.998625   1456.0\n",
      "3   0.982143  0.956522  0.969163    115.0\n",
      "4   0.998957  0.989669  0.994292   1936.0\n",
      "‚úÖ Metrics saved to C:\\Users\\bhand\\ids-bias-project\\results\\bias_underrepresented_class1.json\n",
      "‚è±Ô∏è Time taken: 16.66 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhand\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\bhand\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\bhand\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Drop 80% of class 1\n",
    "rare_class = 1\n",
    "drop_frac = 0.8\n",
    "\n",
    "mask = np.where(y_train == rare_class)[0]\n",
    "drop_n = int(len(mask) * drop_frac)\n",
    "drop_idx = np.random.choice(mask, drop_n, replace=False)\n",
    "\n",
    "X_train_under = X_train.drop(X_train.index[drop_idx])\n",
    "y_train_under = np.delete(y_train, drop_idx)\n",
    "\n",
    "print(f\"Dropped {drop_n} samples from class {rare_class}. New train shape: {X_train_under.shape}\")\n",
    "\n",
    "# Train\n",
    "model_under = train_and_evaluate(X_train_under, y_train_under, X_val, y_val, \"underrepresented_class1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77d016bb-279a-4238-8d79-de516362304a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 29286 samples from class 0. New train shape: (40714, 70)\n",
      "\n",
      "üîπ Running scenario: label_imbalance_class0\n",
      "‚úÖ Model trained.\n",
      "Confusion Matrix (first 5x5 block):\n",
      " [[25126     4     1     2     5]\n",
      " [   12    11     0     0     0]\n",
      " [    3     0  1453     0     0]\n",
      " [    4     0     0   111     0]\n",
      " [   15     0     0     0  1921]]\n",
      "\n",
      "Classification Report (head):\n",
      "   precision    recall  f1-score  support\n",
      "0   0.998093  0.998927  0.998510  25153.0\n",
      "1   0.733333  0.478261  0.578947     23.0\n",
      "2   0.999312  0.997940  0.998625   1456.0\n",
      "3   0.982301  0.965217  0.973684    115.0\n",
      "4   0.997404  0.992252  0.994821   1936.0\n",
      "‚úÖ Metrics saved to C:\\Users\\bhand\\ids-bias-project\\results\\bias_label_imbalance_class0.json\n",
      "‚è±Ô∏è Time taken: 6.27 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhand\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\bhand\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\bhand\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Drop 50% of class 0\n",
    "major_class = 0\n",
    "mask = np.where(y_train == major_class)[0]\n",
    "drop_n = int(len(mask) * 0.5)\n",
    "drop_idx = np.random.choice(mask, drop_n, replace=False)\n",
    "\n",
    "X_train_imb = X_train.drop(X_train.index[drop_idx])\n",
    "y_train_imb = np.delete(y_train, drop_idx)\n",
    "\n",
    "print(f\"Dropped {drop_n} samples from class {major_class}. New train shape: {X_train_imb.shape}\")\n",
    "\n",
    "# Train\n",
    "model_imb = train_and_evaluate(X_train_imb, y_train_imb, X_val, y_val, \"label_imbalance_class0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fad7aef-2275-471b-9060-0bbfcdf5e857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added label noise to 3500 samples\n",
      "\n",
      "üîπ Running scenario: label_noise_5pct\n",
      "‚úÖ Model trained.\n",
      "Confusion Matrix (first 5x5 block):\n",
      " [[25048    14    12     9     9]\n",
      " [   13    10     0     0     0]\n",
      " [    3     0  1451     0     1]\n",
      " [    4     0     0   108     0]\n",
      " [   16     2     2     0  1915]]\n",
      "\n",
      "Classification Report (head):\n",
      "   precision    recall  f1-score  support\n",
      "0   0.997889  0.995826  0.996856  25153.0\n",
      "1   0.333333  0.434783  0.377358     23.0\n",
      "2   0.984396  0.996566  0.990444   1456.0\n",
      "3   0.915254  0.939130  0.927039    115.0\n",
      "4   0.993773  0.989153  0.991457   1936.0\n",
      "‚úÖ Metrics saved to C:\\Users\\bhand\\ids-bias-project\\results\\bias_label_noise_5pct.json\n",
      "‚è±Ô∏è Time taken: 35.27 seconds\n"
     ]
    }
   ],
   "source": [
    "# Flip 5% labels randomly\n",
    "noise_frac = 0.05\n",
    "n_noise = int(len(y_train) * noise_frac)\n",
    "noise_idx = np.random.choice(len(y_train), n_noise, replace=False)\n",
    "\n",
    "y_train_noisy = y_train.copy()\n",
    "y_train_noisy[noise_idx] = np.random.randint(0, len(np.unique(y_train)), n_noise)\n",
    "\n",
    "print(f\"Added label noise to {n_noise} samples\")\n",
    "\n",
    "# Train\n",
    "model_noise = train_and_evaluate(X_train, y_train_noisy, X_val, y_val, \"label_noise_5pct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f71120-1e3f-4b3c-85ef-382e6a9f31a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
